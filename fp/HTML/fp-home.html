<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <link rel="stylesheet" href="../CSS/style.css">
        <title>FATE</title>
    </head>

    <body>

        <header>
            <h1>
                <a href="../HTML/fp-home.html">F.A.T.E.</a>
            </h1>
        </header>

        <div class="content">

            <nav>
                <h2 id="selected">
                    <a href="../HTML/fp-home.html">What is FATE?</a>
                </h2>
                
                <h2>
                    <a href="../HTML/fp-cases.html">Cases of algorithmic bias</a>
                </h2>
            </nav>
    
            <div class="what-is-fate">
    
                <div class="fairness">
                    <div class="fairness-images">
                        <img class="fairness1" src="../assets/home/fairness1.jpg" alt="scale">
                        <img class="fairness2" src="../assets/home/fairness2.jpg" alt="scale">
                    </div>
                    <h3>Fairness</h3>
                    <p>Fairness is a complex term with many different meanings depending on its context in cases of algorithmic bias. Does fairness mean equality or equity? Can it achieve both equality and equity? In what instances would equality or equity result in increased fairness? Although the term may seem simple, when applied to real-life circumstances, the impacts can be dramatically different.</p>
                </div>
    
                <div class="accountability">
                    <div class="accountability-images">
                        <img class="accountability1" src="../assets/home/accountability2.jpg" alt="hand low">
                        <img class="accountability2" src="../assets/home/accountability1.jpg" alt="hand high">
                    </div>
                    <h3>Accountability</h3>
                    <p>Who / what should be held accountable for the harms and injustices of bias in technology? In many instances of algorithmic bias, there are three main actors: the organization, the programmers, and society. Should the organization be held accountable for allowing or even encouraging biases to occur? Should programmers be held accountable because they are the ones who are making the algorithms and therefore have the opportunities to not build the technology? Or should society be held accountable because the biases originate outside of the technology sphere in present-day society and historical prejudices? And once we decide who should be held accountable, what would be appropriate reparations?</p>
                </div>
    
                <div class="transparency">
                    <div class="transparency-images">
                        <img class="transparency1" src="../assets/home/transparency2.jpg" alt="squares">
                        <img class="transparency2" src="../assets/home/transparency1.jpg" alt="squares inverted">
                    </div>
                    <h3>Transparency</h3>
                    <p>Transparency is the openness and visibility of algorithmic models to users, especially populations who are most negatively impacted. Although increased transprency of algorithms seems like a good thing, oftentimes it can lead to information overload and actually decrease user's trust. Additionally, the algorithms must be presented in an explainable way in order for it to be useful.</p>
                </div>
    
                <div class="ethics">
                    <div class="ethics-images">
                        <img class="ethics1" src="../assets/home/ethics2.jpg" alt="hand with money">
                        <img class="ethics2" src="../assets/home/ethics1.jpg" alt="hand with heart">
                    </div>
                    <h3>Ethics</h3>
                    <p>Ethics is the moral principles that are taken into consideration when developing artificial intelligence technology. Who is this technology for? How will this help or hurt the population it is intended for as well as the untargeted population? Ethical AI must be developed keeping all people in mind, especially populations that are more likely to experience negative impacts.</p>
                </div>
    
            </div>

        </div>

    </body>

</html>

